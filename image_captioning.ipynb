{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "Get dataset and split into individual sentences\n",
    "\n",
    "Create word corpus (vocabulary list from dataset)\n",
    "\n",
    "Calculate total number of unique words, +1 for the padding \"words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/captions.txt') as f:\n",
    "    captions = [lines.strip().split(',') for lines in f.readlines()]\n",
    "\n",
    "captions = captions[1:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                                   1     2     3     4     5  \\\n",
       "0  A child in a pink dress is climbing up a set o...  None  None  None  None   \n",
       "\n",
       "      6  \n",
       "0  None  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.DataFrame(captions)\n",
    "captions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40455</td>\n",
       "      <td>40455</td>\n",
       "      <td>2447</td>\n",
       "      <td>715</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8091</td>\n",
       "      <td>39929</td>\n",
       "      <td>2288</td>\n",
       "      <td>705</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1626754053_81126b67b6.jpg</td>\n",
       "      <td>\"Two dogs</td>\n",
       "      <td>\"</td>\n",
       "      <td>and a backpack .\"</td>\n",
       "      <td>sitting</td>\n",
       "      <td>orange and red costumes for a parade .\"</td>\n",
       "      <td>are waving to the crowd along the parade rout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0           1     2                   3  \\\n",
       "count                       40455       40455  2447                 715   \n",
       "unique                       8091       39929  2288                 705   \n",
       "top     1626754053_81126b67b6.jpg  \"Two dogs      \"   and a backpack .\"   \n",
       "freq                            5          37    19                   3   \n",
       "\n",
       "                4                                         5  \\\n",
       "count          64                                         5   \n",
       "unique         64                                         5   \n",
       "top      sitting    orange and red costumes for a parade .\"   \n",
       "freq            1                                         1   \n",
       "\n",
       "                                                        6  \n",
       "count                                                   1  \n",
       "unique                                                  1  \n",
       "top      are waving to the crowd along the parade rout...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i in [2,3,4,5,6]:\n",
    "    idx += list(captions[captions[i].notnull()].index)\n",
    "\n",
    "idx = list(set(idx))\n",
    "\n",
    "for index in idx:\n",
    "    captions.iloc[idx[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a very small dog jumps on an older man .\"    '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(captions.iloc[idx[0],[2,3,4,5,6]].fillna(\"\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus: # for each sentence in dataset\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0] # tokenize each sentence\n",
    "\tfor i in range(1, len(token_list)): # create n-grams for each sentence so that\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences so that inputs will have same length\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label (last word in sentence)\n",
    "sequence, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=total_words) #convert them to categorical and one hot encode them so that it can predict which word from the vocab it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "history = model.fit(sequence, labels, epochs=100, verbose=1)\n",
    "#print model.summary()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"I've got a bad feeling about this\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_discriminator(self):\n",
    "        image_input = Input(shape=self.image_size)\n",
    "\n",
    "        x = self.conv_block(image_input, 128, 4, 2, 'same', use_batch_norm=True, use_bias=False, activation=LeakyReLU(alpha=leaky_relu_slope))\n",
    "        x = self.conv_block(x, 128, 4, 2, 'same', use_batch_norm=True, use_bias=False, activation=LeakyReLU(alpha=leaky_relu_slope))\n",
    "        x = self.conv_block(x, 128, 4, 2, 'same', use_batch_norm=True, use_bias=False, activation=LeakyReLU(alpha=leaky_relu_slope))\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        output_score = Dense(1)(x)\n",
    "\n",
    "        return keras.Model(image_input, output_score, name=\"discriminator\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ee5403e18d804ebb44ee52a33f7027b543cc38948065ce95628afdc6386affb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
